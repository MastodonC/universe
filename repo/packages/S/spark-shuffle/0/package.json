{
  "packagingVersion": "3.0",
  "minDcosReleaseVersion": "1.7",
  "name": "spark-shuffle",
  "version": "0.1-0.1",
  "scm": "https://github.com/NBCUAS/dcos-spark-shuffle-service",
  "maintainer": "support@mesosphere.io",
  "website": "https://github.com/NBCUAS/dcos-spark-shuffle-service/blob/master/SPARK-IN-DCOS.md",
  "description": "During large shuffles Spark spits out bunch of temporary shuffle blocks to local directory configured by spark.local.dir property. When executor stops, external shuffle service keeps track of these files locations and makes sure that they are not removed while the driver is still alive, so that they can be retrieved later by other executors.\n\nBy default Spark writes this temporary blocks to /tmp, which works fine when Spark is running on bare metal. However when it's running with dockerized executors (default way of running in DC/OS) default location is inside the running Docker container and all the data goes away when executor stops.\n\nA solution is to map underlying host volume into Spark Executors and Spark Mesos Shuffle Service, and update spark.local.dir configuration.\n\nThis package provides that mapping and shuffling service seamlessly across a DC/OS cluster.\n\nInstallation Documentation: https://github.com/dcos/examples/tree/master/1.8/spark-shuffle",
  "tags": ["spark", "shuffle", "resource management", "zeppelin"],
  "preInstallNotes": "This DC/OS Service is currently EXPERIMENTAL. There may be bugs, incomplete features, incorrect documentation, or other discrepancies.",
 "postInstallNotes": "Service installed.",
 "postUninstallNotes": "Service uninstalled.",
  "licenses": [
    {
      "name": "Apache License",
      "url": "https://github.com/apache/spark/blob/master/LICENSE"
    }
  ]
}
